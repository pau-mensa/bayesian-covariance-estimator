{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55d22b5-2285-47a4-b54d-c6f6587bad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the returns data\n",
    "rets = pd.read_csv('data/returns.csv', index_col=0)\n",
    "future_returns = rets[-252:]\n",
    "returns = rets[-252*2:-252]\n",
    "\n",
    "# We use the penultime year as the returns matrix. The last year of the dataset will be used to check the fit goodness.\n",
    "\n",
    "#print(returns.tail())\n",
    "#print(future_returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38bfc98-54a1-4a7e-93e4-dd92e645cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [L]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 03:11&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 192 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "\n",
    "# Convert returns to numpy array\n",
    "returns_data = returns.values\n",
    "\n",
    "# Define the Bayesian model\n",
    "with pm.Model() as model:\n",
    "    # Lewandowski-Kurowicka-Joe Cholesky covariance matrix. This is a probability distribution over positive definite matrices.\n",
    "    L, corr, std = pm.LKJCholeskyCov('L', n=returns_data.shape[1], eta=50, sd_dist=pm.HalfNormal.dist(5.0), compute_corr=True)\n",
    "    \n",
    "    # Reconstruct the covariance matrix from L\n",
    "    sigma = pm.Deterministic('sigma', L.dot(L.T))\n",
    "    \n",
    "    # Observed returns data\n",
    "    returns_obs = pm.MvNormal('returns_obs', mu=np.zeros(returns_data.shape[1]), chol=L, observed=returns_data)\n",
    "    \n",
    "    # Perform inference\n",
    "    trace = pm.sample(2000, return_inferencedata=False, tune=1000)\n",
    "\n",
    "# Extract the posterior mean of the covariance matrix\n",
    "posterior_cov_matrix = np.mean(trace['sigma'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fcc788-5c65-4adb-8837-9f4909d371d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import LedoitWolf, OAS\n",
    "\n",
    "# Ledoit-Wolf shrinkage estimator\n",
    "lw = LedoitWolf()\n",
    "lw_cov_matrix = lw.fit(returns_data).covariance_\n",
    "\n",
    "oas = OAS()\n",
    "oas_cov_matrix = oas.fit(returns_data).covariance_\n",
    "\n",
    "# We use two known estimators, the ledoit wolf and the oracle approximating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a355a41-87fd-4e34-805f-81a877a0c224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Log-Likelihood: 27.69286479363813\n",
      "Ledoit-Wolf Log-Likelihood: 27.502390445199936\n",
      "Ledoit-Wolf Log-Likelihood: 27.512044369390207\n",
      "Sample covariance Log-Likelihood: 27.487805936692986\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Convert future returns to numpy array\n",
    "future_returns_data = future_returns.values\n",
    "\n",
    "# We will use the log likelihood to check the goodness of fit.\n",
    "def log_likelihood(cov_matrix, data):\n",
    "    mean_returns = np.zeros(cov_matrix.shape[0])\n",
    "    mvn = multivariate_normal(mean=mean_returns, cov=cov_matrix)\n",
    "    return mvn.logpdf(data).mean()\n",
    "\n",
    "# Calculate log-likelihood for each covariance matrix\n",
    "bayesian_log_likelihood = log_likelihood(posterior_cov_matrix, future_returns_data)\n",
    "ledoitwolf_log_likelihood = log_likelihood(lw_cov_matrix, future_returns_data)\n",
    "oas_log_likelihood = log_likelihood(oas_cov_matrix, future_returns_data)\n",
    "sample_log_likelihood = log_likelihood(returns.cov(), future_returns_data)\n",
    "\n",
    "print(f\"Bayesian Log-Likelihood: {bayesian_log_likelihood}\")\n",
    "print(f\"Ledoit-Wolf Log-Likelihood: {ledoitwolf_log_likelihood}\")\n",
    "print(f\"Ledoit-Wolf Log-Likelihood: {oas_log_likelihood}\")\n",
    "print(f\"Sample covariance Log-Likelihood: {sample_log_likelihood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98fee4b4-5fbe-4de6-8d91-f2191ca13d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we can see that the Bayesian estimator is better than traditional measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd683758-ce86-46e9-a374-09a9b2355d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
